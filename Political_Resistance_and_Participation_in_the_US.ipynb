{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EvUcUf19vv3"
      },
      "outputs": [],
      "source": [
        "# # if you do not have the folder to begin with:\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# %cd content/drive/MyDrive\n",
        "#!git clone https://github.com/MadBeignet/MadBeignet.github.io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBdCfIGwDi6_",
        "outputId": "1fe46762-01cc-4f9a-ade4-fb6d7601ea89"
      },
      "outputs": [],
      "source": [
        "#%cd../../../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zq1aEblvvlX",
        "outputId": "83478412-4388-4401-f0a6-ed3d56eaea7e"
      },
      "outputs": [],
      "source": [
        "# # first, mount your google drive, change to the course folder, pull latest changes, and change to the lab folder.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive',force_remount=True)\n",
        "# %cd content/MadBeignet.github.io\n",
        "# !git pull\n",
        "# %cd Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd './Data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnGWU2vkBBF1"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import figure\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV1aiNAewyWU"
      },
      "source": [
        "Team: Merrilee Montgomery and Maddie Wisinski\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSJx_6RAxn5s"
      },
      "source": [
        "Website Link: https://madbeignet.github.io/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teyMSPGJwyKN"
      },
      "source": [
        "<h1>Project Goals</h1>\n",
        "<p>The team will be looking at the relationship between political participation and political resistance in the United States from 2000-2021 by state.</p> <p>To measure political participation, the team will use voter turnout statistics by state from collected by the Election Project. The election project website derives all its data from individual state websites.</p><p>This project will distinguish between violent and nonviolent political resistance. To measure nonviolent political resistance, this group will use protest frequency and size from Count Love, a group from MIT that began tracking protests amidst the 2017 Women's March. To study violent political resistance, this project will use Profiles of Individual Radicalization in the US (PIRUS) from University of Maryland National Consortium for the Study of Terrorism and Responses to Terrorism (START). The PIRUS Dataset contains informaiton about individuals who's radicalization became apparent through their plotting to engage in violent activity.</p>\n",
        "\n",
        "Election Project: https://www.electproject.org/home\n",
        "\n",
        "Count Love: https://countlove.org/faq.html\n",
        "\n",
        "PIRUS: https://www.start.umd.edu/data-tools/profiles-individual-radicalization-united-states-pirus\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZJB6MYAzo4D"
      },
      "source": [
        "<h1>Voter Turnout: 2000-2022</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32FBdIrd6FP0"
      },
      "source": [
        "<h2>Cleaning the Data</h2><p>The Election Project collects voter turnout data for the general election that occur every two comes in separate CSVs by year. Here we want to read all by-year files into a single DataFrame. To do so, we must account for the following:</p> \n",
        "\n",
        "1.   Years 2000-2010 are in a uniform format, but missing state abbreviation.\n",
        "2.   Years 2012-2020 have an extra column of state abreviation that can be used to create a index value consisting of Year and State Abbreviation.\n",
        "3.   Years 2016-2020 have notes at the end of each csv that must be deleted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5eLI_Zptcdf"
      },
      "source": [
        "<h4>Step 1: Concatenate years 2000-2010</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "jRXeQ6bvWmj7",
        "outputId": "eabf228e-56d5-4655-eea1-bc07d2a54de2"
      },
      "outputs": [],
      "source": [
        "csv_final = pd.read_csv(\"./Voter_Turnouts/2000 November General Election - Turnout Rates.csv\",\n",
        "                        header = None,\n",
        "                        skiprows = 2)#first two rows is header in CSV\n",
        "csv_final['Year']=2000\n",
        "\n",
        "l = []#we will use this to make sure all files loaded\n",
        "for a in range (2002,2012,2):\n",
        "  csv_temp = pd.read_csv(\"./Voter_Turnouts/\"+str(a)+\" November General Election - Turnout Rates.csv\",\n",
        "                         header = None,\n",
        "                         skiprows = 2)#first two rows are headers in csv\n",
        "  csv_temp['Year']=a#As year is incremented,value changes\n",
        "  l.append(1)\n",
        "  csv_final = pd.concat([csv_final,csv_temp],ignore_index = True)\n",
        "final_df = pd.DataFrame(csv_final)\n",
        "print(len(l) == 5)#Test to make sure all files were uploaded, returns true if successful, false else\n",
        "final_df.columns = ['Region', 'VEP Total Ballots Counted', 'VEP Highest Office', 'VAP Highest Office', 'Total Ballots Counted', 'Highest Office', 'Voting-Eligible Population (VEP)', 'Voting-Age Population (VAP)', '% Non-citizen', 'Prison', 'Probation', 'Parole', 'Total Ineligible Felon', 'Overseas Eligible', 'Year']\n",
        "#Rename all columns\n",
        "\n",
        "final_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s1H0jE2RAw5"
      },
      "source": [
        "<h4>Step 2: Drop State Abbreviations and Excess Rows</h4>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czZuFWxqR4PB"
      },
      "source": [
        "<p>To concatenate Voter Turnout from years 2012-2022, we have to remove the abbreviation column and any excess rows (which are usually methodology notes.)</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "nBmiwSHiX8tW",
        "outputId": "6a07311f-9b25-401c-9eda-5c02578c86e9"
      },
      "outputs": [],
      "source": [
        "l = []#we will use this to make sure all files loaded\n",
        "for a in range (2012,2016,2):\n",
        "  csv_temp = pd.read_csv(\"./Voter_Turnouts/\"+str(a)+\" November General Election - Turnout Rates.csv\",\n",
        "                         header = None,\n",
        "                         skiprows = 2,\n",
        "                         names = ['Region', 'VEP Total Ballots Counted', 'VEP Highest Office', 'VAP Highest Office', 'Total Ballots Counted', 'Highest Office', 'Voting-Eligible Population (VEP)', 'Voting-Age Population (VAP)', '% Non-citizen', 'Prison', 'Probation', 'Parole', 'Total Ineligible Felon', 'Overseas Eligible', 'State Abv'])#first two rows are headers in csv\n",
        "  csv_temp['Year']=a#As year is incremented,value changes\n",
        "  csv_temp = csv_temp.iloc[:52]\n",
        "  csv_temp.drop('State Abv',inplace=True,axis=1)\n",
        "  csv_final = pd.concat([csv_final,csv_temp],ignore_index=True)#not sure whats going wrong now, I'll ask Dr. Culotta\n",
        "\n",
        "csv_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0rQqF8CATSY"
      },
      "source": [
        "<p>After 2014, Voter Turnout Data Column names and values vary more. As a result, we must clean each individual dataset to concatenate</p>\n",
        "<p></p>\n",
        "<h4>2018</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "y8pP_w3c6nDx",
        "outputId": "ec9b6894-4248-4abe-c76a-86fb8e0f622e"
      },
      "outputs": [],
      "source": [
        "temp_18 = pd.read_csv(\"./Voter_Turnouts/2018 November General Election - Turnout Rates.csv\",\n",
        "                      names =['Region', 'Estimated or Actual 2018 Total Ballots Counted VEP Turnout Rate', '2018 Vote for Highest Office VEP Turnout Rate', 'Status', 'Source', 'Estimated or Actual 2018 Total Ballots Counted', '2018 Vote for Highest Office', 'Voting-Eligible Population (VEP)', 'Voting-Age Population (VAP)', '% Non-citizen', 'Prison', 'Probation', 'Parole', 'Total Ineligible Felon', 'Overseas Eligible', 'State Abv'],\n",
        "                      skiprows=2,\n",
        "                      header = None)\n",
        "temp_18.drop('Source',inplace=True,axis=1)\n",
        "temp_18.drop('Status',inplace=True,axis=1)\n",
        "temp_18.drop('State Abv',inplace=True,axis=1)\n",
        "csv_final.drop('VAP Highest Office',inplace=True,axis=1)\n",
        "csv_final.columns\n",
        "temp_18.columns = ['Region', 'VEP Total Ballots Counted', 'VEP Highest Office',\n",
        "       'Total Ballots Counted', 'Highest Office',\n",
        "       'Voting-Eligible Population (VEP)', 'Voting-Age Population (VAP)',\n",
        "       '% Non-citizen', 'Prison', 'Probation', 'Parole',\n",
        "       'Total Ineligible Felon', 'Overseas Eligible']\n",
        "temp_18['Year']=2018\n",
        "temp_18 = temp_18.iloc[:52]\n",
        "csv_final = pd.concat([csv_final,temp_18],ignore_index = True)\n",
        "csv_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJWOzKIjBBot",
        "outputId": "12b1aba7-6c94-473f-da21-c625701f6440"
      },
      "outputs": [],
      "source": [
        "l = 'Region,Source,Status,Total Ballots Counted (Estimate),Vote for Highest Office (President),VEP Turnout Rate (Total Ballots Counted),VEP Turnout Rate (Highest Office),Voting-Eligible Population (VEP),Voting-Age Population (VAP),% Non-citizen,Prison,Probation,Parole,Total Ineligible Felon,Overseas Eligible,State Abv'\n",
        "lis = l.split(',')\n",
        "print(lis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzsVp3jsAyXe"
      },
      "source": [
        "<h4>2016</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "YhtjMOIDAO9M",
        "outputId": "17c4f673-c086-44fc-a427-7ef4ddba2361"
      },
      "outputs": [],
      "source": [
        "temp_16 = pd.read_csv(\"./Voter_Turnouts/2016 November General Election - Turnout Rates.csv\",\n",
        "                      names =['Region', 'State Results Website', 'Status', 'VEP Total Ballots Counted', 'VEP Highest Office', 'VAP Highest Office', 'Total Ballots Counted (Estimate)', 'Highest Office', 'Voting-Eligible Population (VEP)', 'Voting-Age Population (VAP)', '% Non-citizen', 'Prison', 'Probation', 'Parole', 'Total Ineligible Felon', 'Overseas Eligible', 'State Abv'],\n",
        "                      skiprows=2,\n",
        "                      header = None)\n",
        "temp_16.drop('Status',inplace=True,axis=1)\n",
        "temp_16.drop('State Results Website',inplace=True,axis=1)\n",
        "temp_16.drop('State Abv',inplace=True,axis=1)\n",
        "temp_16.drop('VAP Highest Office',inplace=True,axis=1)\n",
        "temp_16['Year']=2016\n",
        "temp_16.columns = csv_final.columns\n",
        "temp_16 = temp_16.iloc[:52]\n",
        "csv_final = pd.concat([csv_final,temp_16],ignore_index = True)\n",
        "csv_final\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEc8WAK-IiSg"
      },
      "source": [
        "<h4>2020</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "u0En42BcBVsq",
        "outputId": "642ad02b-6175-4239-ad88-871afb4b4ae6"
      },
      "outputs": [],
      "source": [
        "temp_20 = pd.read_csv(\"./Voter_Turnouts/2020 November General Election - Turnout Rates.csv\",\n",
        "                      names =['Region', 'Source', 'Status', 'Total Ballots Counted (Estimate)', 'Vote for Highest Office (President)', 'VEP Turnout Rate (Total Ballots Counted)', 'VEP Turnout Rate (Highest Office)', 'Voting-Eligible Population (VEP)', 'Voting-Age Population (VAP)', '% Non-citizen', 'Prison', 'Probation', 'Parole', 'Total Ineligible Felon', 'Overseas Eligible', 'State Abv'],\n",
        "                      skiprows=2,\n",
        "                      header = None)\n",
        "temp_20.drop('Source',inplace=True,axis=1)\n",
        "temp_20.drop('Status',inplace=True,axis=1)\n",
        "temp_20.drop('State Abv',inplace=True,axis=1)\n",
        "temp_20 = temp_20[['Region','VEP Turnout Rate (Total Ballots Counted)','VEP Turnout Rate (Highest Office)','Total Ballots Counted (Estimate)', 'Vote for Highest Office (President)', 'Voting-Eligible Population (VEP)', 'Voting-Age Population (VAP)', '% Non-citizen', 'Prison', 'Probation', 'Parole', 'Total Ineligible Felon', 'Overseas Eligible']]\n",
        "temp_20['Year'] = 2020\n",
        "temp_20.columns = csv_final.columns\n",
        "temp_20 = temp_20.iloc[:52]\n",
        "csv_final = pd.concat([csv_final,temp_20],ignore_index = True)\n",
        "csv_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "states_cleaned = []\n",
        "for e in csv_final.Region:\n",
        "    e = str(e).replace('*','')\n",
        "    states_cleaned.append(e)\n",
        "csv_final.Region = states_cleaned\n",
        "\n",
        "pd.unique(csv_final.Region)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eksfMwwqeps1"
      },
      "source": [
        "<h2>Radicalized Individuals in the United States</h2><p>This data set is collected on the individual level. Because we are examining trends on the state level, we will save this Data grouped to the individuals' origin states.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65QG-17ihU8Z"
      },
      "source": [
        "<h4>1. Loading the PIRUS Data</h4><p>The PIRUS data measures 145 categorical and quantitative variables that do not load nicely into COLAB. We have taken the first header line from the CSV an split it into a list that can be passed as column names for the CSV.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAjwA27NfRbh",
        "outputId": "909c8352-a214-4a26-c197-70fab668f416"
      },
      "outputs": [],
      "source": [
        "a = \"Subject_ID,Loc_Plot_State1,Loc_Plot_City1,Loc_Plot_State2,Loc_Plot_City2,Date_Exposure,Plot_Target1,Plot_Target2,Plot_Target3,Attack_Preparation,Op_Security,Changing_Target,Anticp_Fatals_Targ,Internet_Use_Plot,Extent_Plot,Violent,Criminal_Severity,Criminal_Charges,Indict_Arrest,Current_Status,Group_Membership,Terrorist_Group_Name1,Terrorist_Group_Name2,Terrorist_Group_Name3,Actively_Recruited,Recruiter1,Recruiter2,Recruiter3,Actively_Connect,Group_Competition,Role_Group,Length_Group,Clique,Clique_Radicalize,Clique_Connect,Internet_Radicalization,Media_Radicalization,Social_Media,Social_Media_Frequency,Social_Media_Platform1,Social_Media_Platform2,Social_Media_Platform3,Social_Media_Platform4,Social_Media_Platform5,Social_Media_Activities1,Social_Media_Activities2,Social_Media_Activities3,Social_Media_Activities4,Social_Media_Activities5,Social_Media_Activities6,Social_Media_Activities7,Radicalization_Islamist,Radicalization_Far_Right,Radicalization_Far_Left,Radicalization_Single_Issue,Ideological_Sub_Category1,Ideological_Sub_Category2,Ideological_Sub_Category3,Loc_Habitation_State1,Loc_Habitation_City1,Loc_Habitation_State2,Loc_Habitation_City2,Itinerant,External_Rad,Rad_duration,Radical_Behaviors,Radical_Beliefs,US_Govt_Leader,Foreign_Govt_Leader,Event_Influence1,Event_Influence2,Event_Influence3,Event_Influence4,Beliefs_Trajectory,Behaviors_Trajectory,Radicalization_Sequence,Radicalization_Place,Prison_Radicalize,Broad_Ethnicity,Age,Marital_Status,Children,Age_Child,Gender,Religious_Background,Convert,Convert_Date,Reawakening,Reawakening_Date,Citizenship,Residency_Status,Nativity,Time_US_Months,Immigrant_Generation,Immigrant_Source,Language_English,Diaspora_Ties,Education,Student,Education_Change,Employment_Status,Change_Performance,Work_History,Military,Foreign_Military,Social_Stratum_Childhood,Social_Stratum_Adulthood,Aspirations,Abuse_Child,Abuse_Adult,Abuse_type1,Abuse_Type2,Abuse_Type3,Psychological,Alcohol_Drug,Absent_Parent,Overseas_Family,Close_Family,Family_Religiosity,Family_Ideology,Family_Ideological_Level,Prison_Family_Friend,Crime_Family_Friend,Radical_Friend,Radical_Family,Radical_Signif_Other,Relationship_Troubles,Platonic_Troubles,Unstructured_Time,Friendship_Source1,Friendship_Source2,Friendship_Source3,Kicked_Out,Previous_Criminal_Activity,Previous_Criminal_Activity_Type1,Previous_Criminal_Activity_Type2,Previous_Criminal_Activity_Type3,Previous_Criminal_Activity_Age,Gang,Gang_Age_Joined,Trauma,Other_Ideologies,Angry_US,Group_Grievance,Standing\"\n",
        "def listify(mis_string):\n",
        "  return mis_string.split(\",\")\n",
        "pirus_headlist = listify(a)\n",
        "print(pirus_headlist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "Y3cxapS-hBFZ",
        "outputId": "1fa0974a-1d34-4ec5-900c-d644329171a6"
      },
      "outputs": [],
      "source": [
        "pirus_temp = pd.read_csv(\"./PIRUS_May2020/PIRUS_Public_May2020.csv\",\n",
        "                         header=1,\n",
        "                         names = pirus_headlist)\n",
        "pirus_temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0LVTGOVifd3"
      },
      "source": [
        "<h4>2. Filtering and Grouping By States</h2><p> We will only examine radicalized individual since 2000 due to the fact that voter data comes from the 2000-2020 years, and protest data comes from the 2017-2021 years. (This data starts in 1948 and goes through 2018.)\n",
        "\n",
        "We will also use value_counts to determine the different states that from which the radicalized individual originate from. We are assuming that this is also the state in which the individual is mostly likely to engage in popular protest and vote.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "rwqzY1D-jes_",
        "outputId": "0fc96863-fd33-419b-e425-7281bc1ec33b"
      },
      "outputs": [],
      "source": [
        "#Date_Exposure is not comparable because it is of dtype string.\n",
        "#Create column 'Year' of int values that represents the last 2 digit of the year.\n",
        "l = []\n",
        "for val in pirus_temp['Date_Exposure']:\n",
        "  a = val.split('/')\n",
        "  b = a[-1:]\n",
        "  l.append(int(b[0]))\n",
        "pirus_temp['Year'] = l\n",
        "#Any row with 'Year' under 22 occured in the 2000's and is in the scope of this study\n",
        "pirus_temp = pirus_temp[pirus_temp['Year'] <= 22]\n",
        "#Group by state\n",
        "pirus_states_since_2000 = pirus_temp.value_counts('Loc_Habitation_State1')\n",
        "pirus_states_since_2000.plot(kind='bar', figsize=(20, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuoyGEzJr2FS"
      },
      "source": [
        "<h2>Protests in the United States</h2><p>This data set is collected on the event level. Because we are examining trends on the state level, we will save this Data grouped to the protest event location. It is worth noting that popular protest often spreads. This data is harvested by webcrawling for news articles and similar media referencing the protest to a location. Therefore, protests that happened in wave, such as those in response to George Floyd's murder, will appearch multiple times. However, we will still count these as separate events, even if such events are comorbid.</p><p>Because this data set only covers 4 years, we do not have to filter it. We will only group it by state.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D5Xsb3bGtcLa",
        "outputId": "0100adc4-fb85-4715-8f8d-49c24b222369"
      },
      "outputs": [],
      "source": [
        "protests_temp = pd.read_csv(\"./Protests/data.csv\",\n",
        "                         header = 1,\n",
        "                         names = ['Date','Location','Attendees',\n",
        "                         'Event (legacy; see tags)','Tags',\n",
        "                         'Curated','Source','Total_Articles'])\n",
        "protests_temp.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "VIXcC-G8ubPH",
        "outputId": "43ec5374-48a3-4d75-e073-2af8213ff617"
      },
      "outputs": [],
      "source": [
        "#Must create state attribute to groupby state, similar to extracting year, but first create dictionary matching statges to abbreviation.\n",
        "states = [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\"Connecticut\",\"District of Columbia\",\"Delaware\",\"Florida\",\"Georgia\",\"Guam\",\"Hawaii\",\"Idaho\",\"Illinois\",\"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\"Puerto Rico\",\"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"United States\",\"Utah\", \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]\n",
        "abbrev = [\"AL\",\"AK\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DC\",\"DE\",\"FL\",\"GA\",\"GU\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\"KS\",\"KY\",\"LA\",\"ME\",\"MD\",\"MA\",\"MI\",\"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\"NM\",\"NY\",\"NC\",\"ND\",\"OH\",\"OK\",\"OR\",\"PA\",\"PR\",\"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"US\",\"UT\",\"VT\",\"VA\",\"WA\",\"WV\",\"WI\",\"WY\"]\n",
        "states_dict = {}\n",
        "i = 0\n",
        "for name in abbrev:\n",
        "  states_dict[name] = states[i]\n",
        "  i += 1\n",
        "print(states_dict)\n",
        "#create list of state names\n",
        "protests_temp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "q_zIuhWeLb3x",
        "outputId": "dfce2367-ed41-411c-db70-6cc043bcc49e"
      },
      "outputs": [],
      "source": [
        "#Create a list that can be added as a column to the DataFrame, representing the locatiion the protest took place in.\n",
        "l = []\n",
        "for val in protests_temp['Location']:\n",
        "  m = val.split(',')\n",
        "  if len(m) >= 2:\n",
        "    n = m[-1][-2:]\n",
        "    state = states_dict[n.upper()]\n",
        "    l.append(state)\n",
        "  else: #accounting for abnormal cases. implementation based on printing individual cases\n",
        "    if m == 'La Porte County Courthouse in La Porte':\n",
        "      l.append('Indiana')\n",
        "    if m == 'Space':\n",
        "      l.append('New York')\n",
        "    if n == 'WA':\n",
        "      l.append('Washington')\n",
        "    if n == 'DE':\n",
        "      l.append('Delaware')\n",
        "protests_temp['State'] = l\n",
        "#protests_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "ATm-CqSJVOro",
        "outputId": "3bfd3a9a-94e5-4491-c345-46b36aa239cb"
      },
      "outputs": [],
      "source": [
        "protests_by_state = protests_temp.value_counts('State')\n",
        "protests_by_state.plot.barh(figsize=(10,15))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X1nq8VK7kGY"
      },
      "source": [
        "<p>From this bar chart, we can see that California has the highest number of protests. California also had the highest number of radicalized individuals.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CynSOcPXMdXw",
        "outputId": "84be3505-bec3-4ca2-f220-60d46d2e325a"
      },
      "outputs": [],
      "source": [
        "protests_by_state.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_XtJlpDMinS"
      },
      "source": [
        "We can also see that the mean number of protests by state is 718. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXNB6YOcoGCU"
      },
      "source": [
        "<h1>Population Data</h1>\n",
        "Source: Census Bureau. \n",
        "Notes: The years 2020 and 2021 were in different files, so had to join them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "25_4viNDj-nV",
        "outputId": "76193c1b-446b-45d9-8951-f02a9b77b0a5"
      },
      "outputs": [],
      "source": [
        "pop20_21 = pd.read_csv('./Population/2020-2021 Census Bureau Population.csv')\n",
        "#Rename columns due to header reading error\n",
        "pop20_21.rename(columns={'Population Estimate\\n (as of July 1)':'2020','Unnamed: 3':'2021'},inplace=True)\n",
        "#Drop the first 6 rows becausethey are aggregates\n",
        "pop20_21 = pop20_21.iloc[6:]\n",
        "list1 = []\n",
        "for i in pop20_21['Geographic Area']:\n",
        "  i = i[1:]\n",
        "  list1.append(i)\n",
        "pop20_21['Geographic Area'] = list1\n",
        "pop20_21.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "D5n1_9o5mDKZ",
        "outputId": "6df8d1e8-0026-477b-8057-534e481aff76"
      },
      "outputs": [],
      "source": [
        "pop10_19 = pd.read_csv('./Population/nst-est2019-01.csv')\n",
        "#Rename columns due to header reading error\n",
        "pop10_19.rename(columns={'Population Estimate (as of July 1)':'2010','Unnamed: 2':'Estimates Base','Unnamed: 4':'2011','Unnamed: 5':'2012','Unnamed: 5':'2012','Unnamed: 6':'2013','Unnamed: 7':'2014','Unnamed: 8':'2015','Unnamed: 9':'2016','Unnamed: 10':'2017','Unnamed: 11':'2018','Unnamed: 12': '2019'},inplace=True)\n",
        "#Drop the first 6 rows becausethey are aggregates\n",
        "pop10_19 = pop10_19.iloc[6:]\n",
        "list1 = []\n",
        "for i in pop10_19['Geographic Area']:\n",
        "  i = i[1:]\n",
        "  list1.append(i)\n",
        "pop10_19['Geographic Area'] = list1\n",
        "pop10_19.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RO-6a4toDWn"
      },
      "outputs": [],
      "source": [
        "total_population = pop10_19\n",
        "total_population['2020'] = pop20_21['2020']\n",
        "total_population['2021'] = pop20_21['2021']\n",
        "total_population.drop(['April 1, 2010','Estimates Base'],inplace=True,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AVTBqaJKANj",
        "outputId": "13449450-74a0-4b0a-ce73-5ad81726a49c"
      },
      "outputs": [],
      "source": [
        "total_population.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRN0gjBHxHxq"
      },
      "outputs": [],
      "source": [
        "def df_creation(row):\n",
        "  ret_val = pd.DataFrame()\n",
        "  ret_val['Population'] = list(row)[1:]\n",
        "  ret_val['Year'] = total_population.columns[1:]\n",
        "  return ret_val\n",
        "\n",
        "S_pop = {}\n",
        "for index, row in total_population.iterrows():\n",
        "  S_pop[list(row)[0]] = df_creation(row)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax=S_pop['Alabama'].plot(x='Year',y='Population')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "4KC7NeXaK-tL",
        "outputId": "ff981f2e-49a7-4df8-c96a-fbaa650bab26"
      },
      "outputs": [],
      "source": [
        "per_population_growth = total_population.copy()\n",
        "years = [2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021]\n",
        "for i in range(len(years)):\n",
        "    per_population_growth[str(years[len(years) - i - 1])] = total_population[str(years[len(years)- i- 1])]/total_population['2010']-1\n",
        "\n",
        "per_population_growth.drop(['2010'],inplace=True,axis=1)\n",
        "per_population_growth.set_index('Geographic Area').transpose().plot(figsize=(10,15))\n",
        "plt.legend()\n",
        "#plt.yscale(\"log\")\n",
        "plt.xlabel(\"Years\")\n",
        "plt.ylabel(\"Population\")\n",
        "plt.title(\"Population Growth Over Time For Each State\")\n",
        "plt.grid(linestyle=':')\n",
        "\n",
        "handles, labels = plt.gca().get_legend_handles_labels()\n",
        "order = per_population_growth['2021'].sort_values(ascending=False).keys()\n",
        "order = order-6\n",
        "\n",
        "plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order],bbox_to_anchor=(1., 1.0), fancybox=True, shadow=True, ncol=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Percent Population Growth by State**\n",
        "\n",
        "Above is the percentage of population growth of each state based on its initial population in 2010. Each state starts on the value 1 for the year 2010, so 2010 was not included. The legend is sorted by the max value at the end, so it's easier to compare each state's line, and also see which state proportionally grew the most over the decade. This is important because the population growth of a state will affect the number of protests and the number of radicalized individuals, and therefore the number of protests per radicalized individual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.pivot_table(total_population, index='Geographic Area').head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQKk302GYMgA"
      },
      "source": [
        "<h1>Merging Data</h1><p>Both protest and radicalization measure resistance to social or governmental structures. Therefore, it makes sense to join aspects of the data into a very simple table to compare radicalization and protest activity. We will not merge this data on the 'State' attribute, because both datasets have such a large number of variables that the table produced would be unweildy.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GwOd-R6hUda"
      },
      "outputs": [],
      "source": [
        "resistance_data = pd.DataFrame()\n",
        "resistance_data['Radicalized_num'] = pirus_states_since_2000\n",
        "resistance_data['Protest_num'] = protests_by_state\n",
        "resistance_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMiyRBsUlIlX"
      },
      "source": [
        "<p>We can look at the relationship now between the number of protests in a state and the number of radicalized individuals in a state. Unsurprisingly, there is a visually obvious correlation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiyvn4wYlIFn"
      },
      "outputs": [],
      "source": [
        "resistance_data.rename({'Loc_Habitation_State1':'State'},inplace=True)\n",
        "resistance_data.plot(kind='scatter',\n",
        "                     y='Radicalized_num',\n",
        "                     x='Protest_num',\n",
        "                     ylabel = \"Number of People Radicalized\",\n",
        "                     xlabel = \"Number of Protests\",\n",
        "                     figsize=(10,8),\n",
        "                     alpha=0.4,\n",
        "                     color='purple',\n",
        "                     s=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH5k3wHGlc9W"
      },
      "source": [
        "<p>We can compute the correlation between these two variables as follows:</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZX-kKEalb3T"
      },
      "outputs": [],
      "source": [
        "resistance_data['Protest_num'].corr(resistance_data['Radicalized_num'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYpoPUYEpNam"
      },
      "source": [
        "<p>This is a significant, but unsurprising \n",
        "correlation. We can represent the population size of the state through the dot size. </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resistance_data_merged = resistance_data.reset_index().rename(columns={'Loc_Habitation_State1':'State'}).merge(total_population.rename(columns={'Geographic Area':'State',\"2021\":\"Population\"})[[\"State\",\"Population\"]],on='State', how=\"right\").set_index(\"State\")\n",
        "resistance_data_merged.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resistance_data_merged[\"Population\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resistance_data_merged.plot(kind='scatter',\n",
        "                     y='Radicalized_num',\n",
        "                     x='Protest_num',\n",
        "                     ylabel = \"Number of People Radicalized\",\n",
        "                     xlabel = \"Number of Protests\",\n",
        "                     title=\"Number of People Radicalized vs Number of Protests\",\n",
        "                     figsize=(10,8),\n",
        "                     alpha=0.4,\n",
        "                     color='purple',\n",
        "                     #s = resistance_data_merged['Population']\n",
        "                     #s=resistance_data_merged[\"Population\"].apply({lambda x: x/1e4}),\n",
        "                     s=100)\n",
        "plt.xscale(\"log\")\n",
        "plt.yscale(\"log\")\n",
        "x_vals = list(resistance_data_merged.reset_index()[\"Protest_num\"])\n",
        "y_vals = list(resistance_data_merged.reset_index()[\"Radicalized_num\"])\n",
        "states = list(resistance_data_merged.reset_index()[\"State\"])\n",
        "for i in range(len(x_vals)):\n",
        "    plt.text(x_vals[i], y_vals[i], states[i], fontsize=8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Protests and Radicalized Individuals Based On State</h3>\n",
        "<p>It is unsurprising to see the largest states have both the most radicalized individuals as well as protests, so a better perspective would be to normalize each of those values based on population. Below will give a better view on each state's participation in politics</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resistance_data_normalized = resistance_data_merged.copy()\n",
        "resistance_data_normalized[\"Protest_num\"] = resistance_data_normalized[\"Protest_num\"]/resistance_data_normalized[\"Population\"]\n",
        "resistance_data_normalized[\"Radicalized_num\"] = resistance_data_normalized[\"Radicalized_num\"]/resistance_data_normalized[\"Population\"]\n",
        "resistance_data_normalized.plot(kind='scatter',\n",
        "                     y='Radicalized_num',\n",
        "                     x='Protest_num',\n",
        "                     ylabel = \"Number of People Radicalized (Normalized by Population)\",\n",
        "                     xlabel = \"Number of Protests (Normalized by Population)\",\n",
        "                     title=\"Number of People Radicalized vs Number of Protests (Normalized by Population)\",\n",
        "                     figsize=(10,8),\n",
        "                     alpha=0.4,\n",
        "                     color='purple',\n",
        "                     #s = resistance_data_merged['Population']\n",
        "                     s=resistance_data_normalized[\"Population\"].apply({lambda x: x/1e4}))\n",
        "plt.xscale(\"log\")\n",
        "plt.yscale(\"log\")\n",
        "x_vals = list(resistance_data_normalized.reset_index()[\"Protest_num\"])\n",
        "y_vals = list(resistance_data_normalized.reset_index()[\"Radicalized_num\"])\n",
        "\n",
        "for i in range(len(x_vals)):\n",
        "    plt.text(x=x_vals[i], y=y_vals[i], s=states[i], fontsize=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Normalized Protests and Radicalized Individuals</h3>\n",
        "<p>One flaw with the graph above was that it meant nothing. When comparing large sets of data belonging to different areas, it's important to normalize them by some factor, so that the data is proportional instead of its regular value. After normalizing the data, a very interesting but telling picture shows. DC is in the top right, making it the most participatory \"state\" in the United States. This makes sense because it's home to the White House, and many protests likely occur here by others outside of DC. The number of protests in proportion to its population as just a city make it key for political involvement.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1>Models</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Model 1: Preface</h3><p>The Protest data Attendance column is missing values for many events. We will build a model to predict what the attendance would have been based on the issues the protest addressed, the state protest took place in, and the proportion of the radicalized individuals from that state.<p>First, let's look at what issues people protest about most often."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "count = []\n",
        "final = []\n",
        "for tag in protests_temp['Tags']:\n",
        "    temp = tag.split(';')\n",
        "    count.append(len(temp))\n",
        "    final += temp\n",
        "final = pd.unique(final)\n",
        "print(pd.unique(count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "protests_temp.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "protests_iss =protests_temp[['Date','Location','Event (legacy; see tags)', 'Attendees','State','Tags']]\n",
        "protests_iss_known = protests_iss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "l_tags = []\n",
        "for i in range(1,9):\n",
        "    m ='Tag' + str(i)\n",
        "    l_tags.append(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "protests_iss_known.rename(columns={'Event (legacy; see tags)':'Event'},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def categorizer(word):\n",
        "    p_list = [r\"\\s*([Rr]acial)\",\n",
        "    r'\\s*(45)', r\"\\s*([Gg]un\\s[Rr]ights)\",r\"\\s*([Gg]un\\s[Cc]ontrol)\",\n",
        "     r\"\\s*([Oo]ther)\", r\"\\s*([Ee]nvironment)\", \n",
        "     r\"\\s*([Ee]ducation)\",r'\\s*([Hh]ealthcare)',\n",
        "     r\"\\s*([Ii]mmigration)\",r\"\\s*([Ee]xecutive)\", \n",
        "     r\"\\s*([Ii]nternational\\s[Rr]elations)\",\n",
        "     r\"\\s*([Ll]egislative)\",r\"\\s*([Cc]ivil\\s[Rr]ights)\"]\n",
        "    tag_dict = {r\"\\s*([Rr]acial)\":\"Racial\",\n",
        "    r'\\s*(45)':\"45th President\", r\"\\s*([Gg]un\\s[Rr]ights)\":\"Gun Rights\",r\"\\s*([Gg]un\\s[Cc]ontrol)\":\"Gun Control\",\n",
        "     r\"\\s*([Oo]ther)\":'Other', r\"\\s*([Ee]nvironment)\":'Environment', \n",
        "     r\"\\s*([Ee]ducation)\":\"Education\",r'\\s*([Hh]ealthcare)':'Healthcare',\n",
        "     r\"\\s*([Ii]mmigration)\":'Immigration',r\"\\s*([Ee]xecutive)\":'Executive', \n",
        "     r\"\\s*([Ii]nternational\\s[Rr]elations)\":'International Relations',\n",
        "     r\"\\s*([Ll]egislative)\":'Legislative',r\"\\s*([Cc]ivil\\s[Rr]ights)\":'Civil Rights','[]':'Other'}\n",
        "    ret_list = set([])\n",
        "    for w in word.split(';'):\n",
        "        print(w)\n",
        "        for pattern in p_list:\n",
        "            m = re.search(pattern,w)\n",
        "            if m != None:\n",
        "                b = tag_dict[pattern]\n",
        "                if b not in ret_list:\n",
        "                    ret_list.add(b)\n",
        "    return ret_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "events = []\n",
        "for a in protests_iss_known[\"Tags\"]:\n",
        "    events.append(categorizer(a))\n",
        "#eventsssss = protests_iss_known[\"Tags\"].apply({lambda x: categorizer(x)}) # \"Racial Injustice\" if \"Racial Injustice\" in x else \"Gun Rights\" if \"Guns\" in x else \"Other\" if \"Other\" in x else \"Environment\" if \"Environment\" in x else \"Education\" if \"Education\" in x else \"Immigration\" if \"Immigration\" in x else x\n",
        "protests_iss_known[\"Event\"] = events\n",
        "Common_Events = protests_iss_known[\"Event\"].value_counts().head(12).keys()\n",
        "print(len(protests_iss_known[\"Event\"].value_counts()))\n",
        "#protests_iss_known[\"Event\"] = protests_iss_known[\"Event\"].apply({lambda x: x if x in Common_Events else \"Other\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def overlapping_value_count(df,return_dict):\n",
        "    s = df['Event']\n",
        "    for entry in s:\n",
        "        l = list(entry)\n",
        "        for e in l:\n",
        "            if e in return_dict.keys():\n",
        "                return_dict[e] += 1\n",
        "            else:\n",
        "                return_dict[e] = 1\n",
        "    ret_val = pd.DataFrame(list(return_dict.items()),index=range(0,len(return_dict.keys())))\n",
        "    ret_val.columns = ['Tag','Count']\n",
        "    ret_val.set_index('Tag',inplace=True)\n",
        "    return ret_val\n",
        "tag_counts = overlapping_value_count(protests_iss_known,{})\n",
        "tag_counts.plot(y='Count',kind='pie',figsize=(10,10),fontsize=10,legend=True,title='Protest Topics',colors=sns.color_palette('tab20'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>People protest many different issues. Let's look at the top 50.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#How to select out certain Protest issues, when Event attribute is saved to a list:\n",
        "\"\"\"'Racial' in protests_iss_known.iloc[0].Event\n",
        "protests_iss_known[protests_iss_known['Event']&{'Racial'}]\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>Just from looking at this chart, it looks like civil rights, racial justice, guns, and immigration are major issues that people protest about..</p><p>Let's also look at the relationship between the time of year that the protests occur and the number of attendees. We will have to drop rows that do not have attendees listed, and convert the data column to a datetime object. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "protests_iss_known.Date = pd.to_datetime(protests_iss_known.Date)\n",
        "protests_real_test = protests_iss.query('Attendees != Attendees')\n",
        "protests_iss_attendees_known = protests_iss.dropna(subset='Attendees')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "protests_iss_attendees_known.Date.value_counts().plot(figsize=(15,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "protests_real_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Model 1: Building the Model</h1><p>We previously saved the protests with unknown attendees to the DataFrame protests_real_test. Let's revisit that data.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tag_unknown = overlapping_value_count(protests_real_test,{})\n",
        "tag_unknown.plot(y='Count',kind='pie',figsize=(8,8),colors=sns.color_palette('tab20'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>We can build a K-nearest neighbor predictor of the number of Attendees at a protest based on the issues the protest addressed, the state protest took place in, and the proportion of the radicalized individuals from that state</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "protests_iss_known"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#How to select out certain Protest issues, when Event attribute is saved to a list:\n",
        "def issue_search(issue):\n",
        "    return protests_iss_known[protests_iss_known['Event']&{issue}]\n",
        "def state_date(row):\n",
        "    return (row.Date,row.State)\n",
        "def state_year(row):\n",
        "    return (row.Date.year,row.State)\n",
        "def vote_pcnt(tuple):\n",
        "    print('tuple',tuple)\n",
        "    year = tuple[0]\n",
        "    state = tuple[1]\n",
        "    if year%2 != 0:\n",
        "        year -= 1\n",
        "        print(year)\n",
        "    if state not in pd.unique(csv_final.Region):\n",
        "        return ('NaN')\n",
        "    line = str(csv_final[(csv_final.Region == state)&(csv_final.Year == year)]['VEP Highest Office'])\n",
        "    print(line)\n",
        "    pcnt = re.search(r'(....%)',line)\n",
        "    print(pcnt.groups())\n",
        "    return float(pcnt[0][:-1])\n",
        "def get_rads_by_population(tuple):\n",
        "    date = tuple[0]\n",
        "    state = tuple[1]\n",
        "    if state not in pd.unique(total_population['Geographic Area']):\n",
        "        return ('NaN')\n",
        "    radicals = pd.DataFrame(pirus_temp[(pirus_temp.Date_Exposure < date)&(pirus_temp.Loc_Plot_State1 == state)&(pirus_temp.Date_Exposure > '2000-01-01 00:00:00')]).size\n",
        "    population = total_population[total_population['Geographic Area'] == state][str(date.year)]\n",
        "    return population/radicals\n",
        "def to_raw(string):\n",
        "    return fr\"{string}\"\n",
        "\n",
        "votes = []\n",
        "for e in range(0,38096):\n",
        "    pcnt = vote_pcnt(state_year(protests_iss_known.iloc[e]))\n",
        "    votes.append(pcnt)\n",
        "protests_iss_known['State_voters'] = votes\n",
        "\n",
        "all_tags= ['Racial','45th President', 'Gun Rights', 'Gun Control', 'Other', 'Environment', 'Education', 'Healthcare', 'Immigration', 'Executive', 'International Relations', 'Legislative', 'Civil Rights', 'Other']\n",
        "for t in all_tags:\n",
        "    protests_iss_known[t] = [0]*38096\n",
        "    for e in list(issue_search(t).index):\n",
        "        e = int(e)\n",
        "        protests_iss_known.loc[e,t]=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rads = []\n",
        "for e in range(0,38096):\n",
        "    rad = get_rads_by_population(state_date(protests_iss_known.iloc[e]))\n",
        "    rads.append(list(rad)[0])\n",
        "protests_iss_known['Radicals'] = rads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "protests_iss_known"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "protests_real_test = protests_iss_known.query('Attendees != Attendees')\n",
        "protests_iss_attendees_known = protests_iss_known.dropna(subset='Attendees')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "protests_iss_attendees_known"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "protests_real_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"feats = [\"Date\", \"Event\", \"State\"]\n",
        "X_dict = protests_iss_known[feats].to_dict(orient=\"records\")\n",
        "y = protests_iss_known[\"Attendees\"]\n",
        "\n",
        "# specify the pipeline\n",
        "kays = []\n",
        "errors = []\n",
        "cvs = []\n",
        "vec = DictVectorizer(sparse=False)\n",
        "scaler = StandardScaler()\n",
        "for num in range(10,50,3):\n",
        "  model = KNeighborsRegressor(n_neighbors=num)\n",
        "  pipeline = Pipeline([(\"vectorizer\", vec), (\"scaler\", scaler), (\"fit\", model)])\n",
        "  scores = cross_val_score(pipeline, X_dict, y, \n",
        "                         cv=5, scoring=\"neg_mean_squared_error\")\n",
        "  i = 1\n",
        "  errors.append(np.sqrt(np.mean(-scores)))\n",
        "  for error in scores:\n",
        "    kays.append(num)\n",
        "    cvs.append(i)\n",
        "    i+=1\n",
        "\n",
        "for_plot = pd.DataFrame()\n",
        "for_plot['K-value'] = kays\n",
        "for_plot['Division'] = cvs\n",
        "for_plot['Error'] = errors\n",
        "\n",
        "print(for_plot)\"\"\"\n",
        "#for_plot.groupby('Division')['Error'].plot(kind='line',x='K-value',y='Error',legend=True,figsize=(15,8))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Model 2</h3><p>Radicalization and Protests Over Time: We will look at the correlation between radicalized individuals and protests over time. Perhaps there are relationships between radicalization on certain issues and more protests on certain issues. For example, we know that internet searches for \"Straight pride\" peak each year during June, which is Pride Month for LGBTQ+ folks. (https://trends.google.com/trends/explore?date=all&geo=US&q=straight%20pride) Perhaps more discussion around an issue in the form of protests causes more radicalization on the opposing side. We will use time data and issue categories for both radicalized individuals from the PIRUS data and protest events.</p><p>As an exploratory exercise, let's plot both the PIRUS and the protests data over time to see the spikes in activity.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "protests_iss_attendees_known.plot(kind='scatter',x='Date',y='Attendees',figsize=(20,10),s=8,c='red',alpha=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>we see clear spikes in protest participation and protest size.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pirus_temp.Date_Exposure = pd.to_datetime(pirus_temp.Date_Exposure)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pirus_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pirus_temp.set_index('Date_Exposure')\n",
        "rad_counts = pirus_temp.sort_index().value_counts('Date_Exposure',sort=False)\n",
        "rad_counts.plot(x='Date_Exposure',figsize=(20,10))\n",
        "\n",
        "#rad_counts.plot(x='Date_Exposure', y = '0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>Now we can plot protests and radicalization on the same axis, though our protest data only starts at 2017. We will have to filter the radicalization data.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pirus_temp.Year = pd.to_numeric(pirus_temp.Year)\n",
        "since_17 = pirus_temp.loc[pirus_temp.Year>=17]\n",
        "since_17.set_index('Date_Exposure')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rad_counts2 = since_17.sort_index().value_counts('Date_Exposure',sort=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rad_counts2 = rad_counts2.reset_index().rename(columns={\"Date_Exposure\":\"Date\",0:\"freq\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_data = protests_iss_attendees_known[[\"Date\",\"Attendees\"]].merge(rad_counts2[[\"Date\",\"freq\"]], on='Date', how='inner')\n",
        "merged_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "ax2 = ax1.twinx()\n",
        "fig.set_size_inches(18.5, 10.5)\n",
        "\n",
        "ax1.scatter(merged_data[\"Date\"], merged_data[\"Attendees\"], c='blue', s=50, alpha=0.4)\n",
        "ax2.scatter(merged_data[\"Date\"], merged_data[\"freq\"], c='red', s=50, alpha=0.15)\n",
        "plt.title(\"Temporary Title\") # title this\n",
        "ax1.set_xlabel(\"Date\")\n",
        "ax1.set_ylabel(\"Attendees\")\n",
        "ax2.set_ylabel(\"Frequency\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>This chart shows the relationship between protest attendance/number and the number of individuals radicalized. We will have to code protests by issue and radicalized individuals by issue to get a better idea of the relationships between radicalization and protests.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vURkKfoNDjR"
      },
      "source": [
        "<h1>Project Strategy</h1><p>Beyond looking at the aggregate state data, the team will look at relationships between political participation, resistance, and violence over time by year for each state. Additionally, if time permits, the group will look at factors such as party affiliation and interest group affiliation.</p>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "48f9a5c728ca7adcf4e9fefd45f6a2b00fb69173035b799b65e122d35b61a393"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
